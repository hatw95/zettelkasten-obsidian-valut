---
Class: paper
created: 2026-01-20
title: GlovEgo-HOI Bridging the Synthetic-to-Real Gap for Industrial Egocentric Human-Object Interaction Detection
cite_key: spotoGlovEgoHOIBridgingSynthetictoReal2026
year: 2026
author: 
- "[[Alfio Spoto]]" 
- "[[Rosario Leonardi]]" 
- "[[Francesco Ragusa]]" 
- "[[Giovanni Maria Farinella]]"
status:
  - 👀 Queue
tags: 
link: http://arxiv.org/abs/2601.09528
aliases: 
  - GlovEgo-HOI
---

> [!info]+ Cite – [PDF](file:///Users/htw/Zotero/storage/AYML9AT4/Spoto%20et%20al.%20-%202026%20-%20GlovEgo-HOI%20Bridging%20the%20Synthetic-to-Real%20Gap%20for%20Industrial%20Egocentric%20Human-Object%20Interaction%20D.pdf) [Zotero](zotero://open-pdf/library/items/AYML9AT4)
> Github: 
> Youtube: 
> Spoto, A., Leonardi, R., Ragusa, F., & Farinella, G. M. (2026). _GlovEgo-HOI: Bridging the Synthetic-to-Real Gap for Industrial Egocentric Human-Object Interaction Detection_ (No. arXiv:2601.09528). arXiv. [https://doi.org/10.48550/arXiv.2601.09528](https://doi.org/10.48550/arXiv.2601.09528)

> [!tldr]+ Abstract
> Egocentric Human-Object Interaction (EHOI) analysis is crucial for industrial safety, yet the development of robust models is hindered by the scarcity of annotated domain-specific data. We address this challenge by introducing a data generation framework that combines synthetic data with a diffusion-based process to augment real-world images with realistic Personal Protective Equipment (PPE). We present GlovEgo-HOI, a new benchmark dataset for industrial EHOI, and GlovEgo-Net, a model integrating Glove-Head and Keypoint- Head modules to leverage hand pose information for enhanced interaction detection. Extensive experiments demonstrate the effectiveness of the proposed data generation framework and GlovEgo-Net. To foster further research, we release the GlovEgo-HOI dataset, augmentation pipeline, and pre-trained models at: GitHub project.

---
### Summary




---


### ✅ Comments

> [!quote|yellow]+ Highlight ([p. 1](zotero://open-pdf/library/items/AYML9AT4?page=1&annotation=R4EAS76R))
> To this end, in this work, we introduce a new data generation framework specifically designed for industrial applications. We extend the synthetic data generation pipeline proposed in (Leonardi et al., 2022; Leonardi et al., 2024b) with automatic annotations of both work gloves and hand keypoints (Figure 1-atop).
> → **그래서 무엇을 했나**

> [!quote|yellow]+ Image ([p. 2](zotero://open-pdf/library/items/AYML9AT4?page=2&annotation=37PVG4J9))
> ![[900_Settings/920_Attachments/@spotoGlovEgoHOIBridgingSynthetictoReal2026/image-2-x72-y612.png]]

### ❓Questions

> [!quote|red]+ Highlight ([p. 1](zotero://open-pdf/library/items/AYML9AT4?page=1&annotation=S5AS66V4))
> Leveraging our proposed data generation framework, we introduce GlovEgo-HOI, a new benchmark dataset comprising both synthetic and real-world data for hand-object interaction in industrial contexts (Figure 1-a).

> [!quote|red]+ Image ([p. 5](zotero://open-pdf/library/items/AYML9AT4?page=5&annotation=Y6GHDCMB))
> ![[900_Settings/920_Attachments/@spotoGlovEgoHOIBridgingSynthetictoReal2026/image-5-x75-y580.png]]
> → **Image comment**

### 📚 Further Reading

> [!quote|green]+ Highlight ([p. 2](zotero://open-pdf/library/items/AYML9AT4?page=2&annotation=FMFZRFMM))
> Egocentric vision has traditionally relied on kitchen domains with EPIC-KITCHENS-100 (Damen et al., 2021) and VISOR (Darkhalil et al., 2022), which provide rich semantic masks for household tasks. Other foundational works include EGTEA Gaze+ (Li et al., 2021) for attention-driven actions and HOI4D (Liu et al., 2022) for category-level interaction analysis in 4D space.
> → **찾아보자**